{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Getting Started with Python Machine Learning\n",
    "\n",
    "\n",
    "+ Python is a flexible language for rapid prototyping.\n",
    "+ The underlying algorithms are all written in optimized C or C++.\n",
    "+ Thus the resulting code is fast and robust enough to be used in production as well.\n",
    "\n",
    "\n",
    "+ Code for the book available at https://github.com/luispedro/BuildingMachineLearningSystemsWithPython\n",
    "\n",
    "\n",
    "+ Machine Learning is also referred to as Data Mining or Predictive Analysis.\n",
    "\n",
    "\n",
    "#### Machine Learning Workflow (most of the time will be spent in rather mundane tasks)\n",
    "+ Reading in the data and cleaning it\n",
    "+ Exploring and understanding the input data\n",
    "+ Analyzing how best to present the data to the learning algorithm\n",
    "+ Choosing the right model and learning algorithm\n",
    "+ Measuring the performance correctly\n",
    "\n",
    "#### Feature Engineering\n",
    "Often you will not feed the data directly into your machine learning algorithm. Instead you will find that you can refine parts of the data before training. Many times the machine learning algorithm will reward you with increased performance. You will even find that a simple algorithm with refined data generally outperforms a very sophisticated algorithm with raw data. This part of the machine learning workflow is called feature engineering, and is most of the time a very exciting and rewarding challenge\n",
    "\n",
    "#### When Stuck, Use\n",
    "+ http://metaoptimize.com/qa\n",
    "+ http://stats.stackexchange.com\n",
    "+ http://stackoverflow.com\n",
    "+ #machinelearning\n",
    "+ https://freenode.net/\n",
    "+ http://www.TwoToReal.com\n",
    "\n",
    "#### Machine Learning Blogs\n",
    "+ http://blog.kaggle.com\n",
    "\n",
    "#### SciPy.org [SciPy, Pandas, NumPy, Matplotlib, SymPy, IPython]  \n",
    "Python is an interpreted language, and the reason for its popularity is its ability to off load number crunching tasks to lower-layered C or FORTRAN extensions such as NumPy (provides highly optimized multidimensional arrays) and SciPy (uses NumPy data structures to provide a set of fast numerical recipes).\n",
    "+ http://www.scipy-lectures.org/index.html#\n",
    "+ http://scipy.org/docs.html\n",
    "\n",
    "## NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- python version: 3.5.2 |Anaconda 4.0.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]\n",
      "-- numpy version: 1.10.4\n",
      "-- numpy version: 1.10.4\n",
      "-- scipy version: 0.17.0\n",
      "-- scikit-learn version: 0.17.1\n",
      "-- matplotlib version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"-- python version: %s\" % sys.version)\n",
    "\n",
    "# don't do the following in order to avoid name collisions\n",
    "# from numpy import *\n",
    "# instead use this\n",
    "import numpy as np\n",
    "print(\"-- numpy version: %s\" % np.version.full_version)\n",
    "print(\"-- numpy version: %s\" % np.__version__)\n",
    "import scipy as sp\n",
    "print(\"-- scipy version: %s\" % sp.__version__ )\n",
    "import sklearn as skl\n",
    "print(\"-- scikit-learn version: %s\" % skl.__version__)\n",
    "import matplotlib as mpl\n",
    "print(\"-- matplotlib version: %s\" % mpl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- numpy array: [0 1 2 3 4 5]\n",
      "-- dimensions: 1\n",
      "-- shape: \n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "## NumPy array\n",
    "a=np.array([0,1,2,3,4,5])\n",
    "print(\"-- numpy array: %s\" % a)\n",
    "print(\"-- dimensions: %s\" % a.ndim)\n",
    "print(\"-- shape: \"); print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 3x2 matrix: \n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "-- dimensions: 2\n",
      "-- shape: \n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "## Transform a into 2 dimensional matrix.\n",
    "b=a.reshape((3,2))\n",
    "print(\"-- 3x2 matrix: \"); print(b)\n",
    "print(\"-- dimensions: %s\" % b.ndim)\n",
    "print(\"-- shape: \"); print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- b: \n",
      "[[ 0  1]\n",
      " [77  3]\n",
      " [ 4  5]]\n",
      "-- a: \n",
      "[ 0  1 77  3  4  5]\n",
      "-- c: \n",
      "[[ 0  1]\n",
      " [77  3]\n",
      " [ 4  5]]\n",
      "-- a: \n",
      "[ 0  1 77  3  4  5]\n",
      "-- c: \n",
      "[[-99   1]\n",
      " [ 77   3]\n",
      " [  4   5]]\n"
     ]
    }
   ],
   "source": [
    "## NumPy optimization: copies are shallow copies.\n",
    "b[1][0]=77\n",
    "print(\"-- b: \"); print(b)\n",
    "print(\"-- a: \"); print(a)\n",
    "\n",
    "## For deep copy, use copy().\n",
    "c=a.reshape((3,2)).copy()\n",
    "print(\"-- c: \"); print(c)\n",
    "c[0][0]=-99\n",
    "print(\"-- a: \"); print(a)\n",
    "print(\"-- c: \"); print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- d: \n",
      "[1 2 3 4 5]\n",
      "-- d*2: \n",
      "[ 2  4  6  8 10]\n",
      "-- d**2: \n",
      "[ 1  4  9 16 25]\n",
      "-- o: \n",
      "[1, 2, 3, 4, 5]\n",
      "-- o*2: \n",
      "[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n",
      "-- o**2: \n",
      "TypeError: unsupported operand type(s) for ** or pow(): 'list' and 'int'\n"
     ]
    }
   ],
   "source": [
    "## Operations are propagated to the individual elements.\n",
    "d=np.array([1,2,3,4,5])\n",
    "print(\"-- d: \"); print(d)\n",
    "print(\"-- d*2: \"); print(d*2)\n",
    "print(\"-- d**2: \"); print(d**2)\n",
    "\n",
    "## Contrast this with ordinary Python lists.\n",
    "o=[1,2,3,4,5]\n",
    "print(\"-- o: \"); print(o)\n",
    "print(\"-- o*2: \"); print(o*2)\n",
    "print(\"-- o**2: \"); \n",
    "try:\n",
    "    print(o**2)\n",
    "except TypeError as typeError:\n",
    "    print(\"TypeError: \" + str(typeError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- a[np.array([2,3,4])]: \n",
      "[77  3  4]\n",
      "-- a>4: \n",
      "[False False  True False False  True]\n",
      "-- a[a>4]: \n",
      "[77  5]\n",
      "-- trim outliers; a[a>4]=4; a: \n",
      "[0 1 4 3 4 4]\n",
      "-- clip outliers; a.clip(0,4): \n",
      "[0 1 4 3 4 4]\n"
     ]
    }
   ],
   "source": [
    "## Numpy indexing.\n",
    "print(\"-- a[np.array([2,3,4])]: \"); print(a[np.array([2,3,4])])\n",
    "print(\"-- a>4: \"); print(a>4)\n",
    "print(\"-- a[a>4]: \"); print(a[a>4])\n",
    "print(\"-- trim outliers; a[a>4]=4; a: \"); a[a>4]=4; print(a)\n",
    "print(\"-- clip outliers; a.clip(0,4): \"); print(a.clip(0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- e: \n",
      "[  1.   2.  nan   3.   4.]\n",
      "-- np.isnan(e): \n",
      "[False False  True False False]\n",
      "-- e[~np.isnan(e)]\n",
      "[ 1.  2.  3.  4.]\n",
      "-- np.mean(e[~np.isnan(e)])\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "## Numpy NAN.\n",
    "e=np.array([1,2,np.NAN,3,4])\n",
    "print(\"-- e: \"); print(e)\n",
    "print(\"-- np.isnan(e): \"); print(np.isnan(e))\n",
    "print(\"-- e[~np.isnan(e)]\"); print(e[~np.isnan(e)])\n",
    "print(\"-- np.mean(e[~np.isnan(e)])\"); print(np.mean(e[~np.isnan(e)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Normal Python: 0.981800 sec\n",
      "-- Native Numpy: 0.890005 sec\n",
      "-- Good Numpy: 0.014418 sec\n"
     ]
    }
   ],
   "source": [
    "## Comparing runtime\n",
    "## we should strive to use highly optimized NumPy or SciPy extension functions (ex: dot())\n",
    "import timeit as tt\n",
    "normal_py_sec=tt.timeit('sum(x*x for x in range(1000))',number=10000)\n",
    "print(\"-- Normal Python: %f sec\" % normal_py_sec)\n",
    "native_np_sec=tt.timeit('sum(na*na)',setup=\"import numpy as np; na=np.arange(1000)\",number=10000)\n",
    "print(\"-- Native Numpy: %f sec\" % native_np_sec)\n",
    "good_np_sec=tt.timeit('na.dot(na)',setup=\"import numpy as np; na=np.arange(1000)\",number=10000)\n",
    "print(\"-- Good Numpy: %f sec\" % good_np_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- f: \n",
      "[1 2 3]\n",
      "-- f data type: \n",
      "int32\n",
      "-- g: \n",
      "['1' 'stringy']\n",
      "-- g data type: \n",
      "<U11\n",
      "-- h: \n",
      "[1 'stringy' {1, 2, 3}]\n",
      "-- h data type: \n",
      "object\n"
     ]
    }
   ],
   "source": [
    "## Speed comes at a price\n",
    "## NumPy arrays can hold only one data type\n",
    "f=np.array([1,2,3])\n",
    "print(\"-- f: \"); print(f)\n",
    "print(\"-- f data type: \"); print(f.dtype)\n",
    "\n",
    "## Numpy coerces to the most reasonable common data type\n",
    "g=np.array([1,\"stringy\"])\n",
    "print(\"-- g: \"); print(g)\n",
    "print(\"-- g data type: \"); print(g.dtype)\n",
    "h=np.array([1,\"stringy\",set([1,2,3])])\n",
    "print(\"-- h: \"); print(h)\n",
    "print(\"-- h data type: \"); print(h.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the complete namespace of NumPy is also accessible via SciPy\n",
    "sp.dot is np.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScipPy packages functionalities\n",
    "\n",
    "#### cluster\n",
    "+ Hierarchical clustering (cluster.hierarchy)\n",
    "+ Vector quantization / k-means (cluster.vq)\n",
    "\n",
    "#### constants\n",
    "+ Physical and mathematical constants\n",
    "+ Conversion methods\n",
    "\n",
    "#### fftpack\n",
    "+ Discrete Fourier transform algorithms\n",
    "\n",
    "#### integrate\n",
    "+ Integration routines\n",
    "\n",
    "#### interpolate\n",
    "+ Interpolation (linear, cubic, and so on)\n",
    "\n",
    "#### io\n",
    "+ Data input and output\n",
    "\n",
    "#### linalg\n",
    "+ Linear algebra routines using the optimized BLAS and LAPACK libraries\n",
    "\n",
    "#### ndimage\n",
    "+ n-dimensional image package\n",
    "\n",
    "#### odr\n",
    "+ Orthogonal distance regression\n",
    "\n",
    "#### optimize\n",
    "+ Optimization (finding minima and roots)\n",
    "\n",
    "#### signal\n",
    "+ Signal processing\n",
    "\n",
    "#### sparse\n",
    "+ Sparse matrices\n",
    "\n",
    "#### spatial\n",
    "+ Spatial data structures and algorithms\n",
    "\n",
    "#### special\n",
    "+ Special mathematical functions such as Bessel or Jacobian\n",
    "\n",
    "#### stats\n",
    "+ Statistics toolkit\n",
    "\n",
    "### Most interesting for us\n",
    "+ scipy.stats\n",
    "+ scipy.interpolate\n",
    "+ scipy.cluster\n",
    "+ scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first application of machine learing\n",
    "\n",
    "MLaaS sells the service of providing machine learning algorithms via HTTP. The question is, when will we hit the limit of our current infrastructure, which we estimated to be at 100,000 requests per hour. We would like to know in advance when we have to request additional servers in the cloud to serve all the incoming requests successfully without paying for unused ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   2.27200000e+03]\n",
      " [  2.00000000e+00              nan]\n",
      " [  3.00000000e+00   1.38600000e+03]\n",
      " [  4.00000000e+00   1.36500000e+03]\n",
      " [  5.00000000e+00   1.48800000e+03]\n",
      " [  6.00000000e+00   1.33700000e+03]\n",
      " [  7.00000000e+00   1.88300000e+03]\n",
      " [  8.00000000e+00   2.28300000e+03]\n",
      " [  9.00000000e+00   1.33500000e+03]\n",
      " [  1.00000000e+01   1.02500000e+03]]\n",
      "(743, 2)\n"
     ]
    }
   ],
   "source": [
    "## reading in the data\n",
    "data=sp.genfromtxt(\"ch01\\data\\web_traffic.tsv\",delimiter=\"\\t\")\n",
    "print(data[:10,])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- x[:10,]: \n",
      "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]\n",
      "-- y[:10,]: \n",
      "[ 2272.    nan  1386.  1365.  1488.  1337.  1883.  2283.  1335.  1025.]\n",
      "-- nan_sum: \n",
      "8\n",
      "-- nan%: \n",
      "1.07671601615\n",
      "-- x[:10,]: \n",
      "[  1.   3.   4.   5.   6.   7.   8.   9.  10.  11.]\n",
      "-- y[:10,]: \n",
      "[ 2272.  1386.  1365.  1488.  1337.  1883.  2283.  1335.  1025.  1139.]\n"
     ]
    }
   ],
   "source": [
    "## processing and cleaning the data\n",
    "x=data[:,0]\n",
    "print(\"-- x[:10,]: \")\n",
    "print(x[:10,])\n",
    "\n",
    "y=data[:,1]\n",
    "print(\"-- y[:10,]: \")\n",
    "print(y[:10,])\n",
    "\n",
    "nan_sum=sp.sum(sp.isnan(y))\n",
    "print(\"-- nan_sum: \")\n",
    "print(nan_sum)\n",
    "\n",
    "# as only 8 entries are nan out of 743, we can afford to remove them\n",
    "print(\"-- nan%: \")\n",
    "print(nan_sum/data.shape[0]*100)\n",
    "\n",
    "x=x[~sp.isnan(y)]\n",
    "print(\"-- x[:10,]: \")\n",
    "print(x[:10,])\n",
    "\n",
    "\n",
    "y=y[~sp.isnan(y)]\n",
    "print(\"-- y[:10,]: \")\n",
    "print(y[:10,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
