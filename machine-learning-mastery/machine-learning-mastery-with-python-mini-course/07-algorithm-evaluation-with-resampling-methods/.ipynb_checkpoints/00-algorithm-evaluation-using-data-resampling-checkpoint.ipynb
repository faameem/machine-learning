{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference:\n",
    "+ [machinelearningmastery: data resampling](http://machinelearningmastery.com/evaluate-performance-machine-learning-algorithms-python-using-resampling/)\n",
    "\n",
    "To avoid overfitting, we canâ€™t train a machine learning algorithm on a dataset and use predictions from this same dataset to evaluate machine learning algorithms.\n",
    "\n",
    "We must evaluate our machine learning algorithms on data that is not used to train the algorithm.\n",
    "\n",
    "The evaluation is an estimate that we can use to talk about how well we think the algorithm may actually do in practice. It is not a guarantee of performance.\n",
    "\n",
    "Once we estimate the performance of our algorithm, we can then re-train the final algorithm on the entire training dataset and get it ready for operational use.\n",
    "\n",
    "# Tips #\n",
    "+ Generally k-fold cross validation is the gold-standard for evaluating the performance of a machine learning algorithm on unseen data with k set to 3, 5, or 10.\n",
    "+ Using a train/test split is good for speed when using a slow algorithm and produces performance estimates with lower bias when using large datasets.\n",
    "+ Techniques like leave-one-out cross validation and repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed and dataset size.\n",
    "\n",
    "# Train and Test Sets #\n",
    "\n",
    "**Pluses**\n",
    "+ Fast\n",
    "+ Good for large datasets\n",
    "\n",
    "**Minuses**\n",
    "+ High variance (differences in train and test datasets can result in differences in accuracy estimation)\n",
    "\n",
    "In addition to specifying the size of the split, we also specify the random seed. Because the split of the data is random, we want to ensure that the results are reproducible. \n",
    "This is important if we want to compare this result to the estimated accuracy of another machine learning algorithm or the same algorithm with a different configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.591%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set (67% / 33%)\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: {:.3%}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-fold Cross Validation #\n",
    "\n",
    "For modest sized datasets in the thousands or tens of thousands of records, k values of 3, 5 and 10 are common.\n",
    "\n",
    "**Pluses**\n",
    "+ Less variance than single train-test set split.\n",
    "\n",
    "**Minuses**\n",
    "+ Computationally more expensive than single train-test set split, especially for big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: mean=76.951%, std=4.841%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: mean={:.3%}, std={:.3%}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave One Out Cross Validation #\n",
    "\n",
    "The size of the fold is 1 as [k] is set to the number of observations in the dataset.\n",
    "\n",
    "**Pluses**\n",
    "+ More reasonable estimate of accuracy for the model on unseen data.\n",
    "\n",
    "**Minuses**\n",
    "+ Computationally more expensive than k-fold cross validation.\n",
    "+ More variance than k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: mean=76.823%, std=42.196%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Leave One Out Cross Validation\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_instances = len(X)\n",
    "loocv = cross_validation.LeaveOneOut(n=num_instances)\n",
    "model = LogisticRegression()\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Accuracy: mean={:.3%}, std={:.3%}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated Random Test-Train Splits #\n",
    "\n",
    "Create a random split of the data like the train/test split, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross validation.\n",
    "\n",
    "**Pluses**\n",
    "+ Fast as the train/test split.\n",
    "+ Reduction in variance as k-fold cross validation.\n",
    "\n",
    "**Minuses**\n",
    "+ Repetitions may include much of the same data in the train or the test split from run to run, introducing redundancy into the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: mean=76.535%, std=1.672%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Shuffle Split Cross Validation\n",
    "# data split = 67% / 33%; repetition = 10 times\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_samples = 10\n",
    "test_size = 0.33\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.ShuffleSplit(n=num_instances, n_iter=num_samples, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: mean={:.3%}, std={:.3%}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
