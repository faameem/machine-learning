{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2438799a-f3f9-44c2-9e1d-cf6a856674c1"
    }
   },
   "source": [
    "> Reference:\n",
    "+ [machinelearningmastery: evaluation metrics](http://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/)\n",
    "+ [machinelearningmasterry: ROC](http://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/)\n",
    "    - **TODO: read**\n",
    "+ [scikit-learn: model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "    - **TODO: read**\n",
    "+ [scikit-learn: Classification Report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support)\n",
    "    \n",
    "**NOTE**\n",
    "+ Some evaluation metrics (like mean squared error) are naturally descending scores (the smallest score is best) and as such are reported as negative by the cross_validation.cross_val_score() function. This is important to note, because some scores will be reported as negative that by definition can never be negative.\n",
    "\n",
    "# Classification Metrics #\n",
    "+ Classification Accuracy.\n",
    "+ Logarithmic Loss.\n",
    "+ Area Under ROC Curve.\n",
    "+ Confusion Matrix.\n",
    "+ Classification Report.\n",
    "\n",
    "### 1: Classification: Accuracy ###\n",
    "\n",
    "+ Classification accuracy is the number of correct predictions made as a ratio of all predictions made.\n",
    "+ It is the most misused metric. It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "6de1e90c-0e6c-4229-8b2f-5f9f39cdfcc4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: mean=76.951%, std=4.841%\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Accuracy\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: mean={:.3%}, std={:.3%}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Classification: Logarithmic Loss (logloss) ###\n",
    "\n",
    "+ Evaluates the predictions of probabilities of membership to a given class. \n",
    "+ The scalar probability between 0 and 1 can be seen as a measure of confidence for a prediction by an algorithm.\n",
    "+ Smaller logloss is better with 0 representing a perfect logloss.\n",
    "+ Commonly used in multinomial logistic regression and neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: mean=-49.250%, std=4.704%\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification LogLoss\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'log_loss'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"LogLoss: mean={:.3%}, std={:.3%}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Classification: Area Under ROC Curve (AUC) ##\n",
    "+ Metric for binary classificatin to discriminate between positive and negative classes.\n",
    "+ An area of:\n",
    "    - **1** means all predictions made perfectly\n",
    "    - **0.5** means predictions as good as random\n",
    "+ A binary classification problem is really a trade-off between sensitivity and specificity.\n",
    "    - **Sensitivity** is the true positive rate also called the recall. It is the number instances from the positive (first) class that actually predicted correctly.\n",
    "    - **Specificity** is also called the true negative rate. Is the number of instances from the negative class (second) class that were actually predicted correctly.\n",
    "\n",
    "The Example below shows the AUC is relatively close to 1 and greater than 0.5, suggesting some skill in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: mean=0.824, std=0.041\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: mean={:.3f}, std={:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Classification: Confusion Matrix ###\n",
    "+ The confusion matrix is a handy presentation of the accuracy of a model with two or more classes.\n",
    "+ In the example below, although the array is printed without headings, you can see that the majority of the predictions fall on the diagonal line of the matrix (which are correct predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Classification: Classification Report ###\n",
    "+ The **precision** is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "+ The **recall** is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "+ The **F-beta** score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0. The F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important.\n",
    "+ The **support** is the number of occurrences of each class in y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics #\n",
    "+ Mean Absolute Error.\n",
    "+ Mean Squared Error.\n",
    "+ R^2.\n",
    "\n",
    "### 1: Regression: Mean Absolute Error ###\n",
    "+ It is the sum of the absolute differences between predictions and actual values.\n",
    "+ The measure gives an idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting).\n",
    "+ A value of 0 indicates no error or perfect predictions. Like logloss, this metric is inverted by the cross_val_score() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: mean=-4.005, std=2.084\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MAE\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearRegression()\n",
    "scoring = 'mean_absolute_error'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MAE: mean={:.3f}, std={:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Regression: Mean Squared Error (MSE or RMSE) ###\n",
    "+ It provides a gross idea of the magnitude of error.\n",
    "+ Taking the square root of the mean squared error converts the units back to the original units of the output variable and can be meaningful for description and presentation.\n",
    "+ This metric too is inverted so that the results are increasing. **Remember to take the absolute value before taking the square root if you are interested in calculating the RMSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: mean=-34.705, std=45.574\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MSE\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearRegression()\n",
    "scoring = 'mean_squared_error'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MSE: mean={:.3f}, std={:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Regression: R Squared (R^2) ###\n",
    "+ It provides an indication of the goodness of fit of a set of predictions to the actual values. In statistical literature, this measure is called the coefficient of determination.\n",
    "+ This is a value between 0 and 1 for no-fit and perfect fit respectively.\n",
    "+ In the example, the predictions have a poor fit to the actual values with a value close to zero and less than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: mean=0.203, std=0.595\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression R^2\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"R^2: mean={:.3f}, std={:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
